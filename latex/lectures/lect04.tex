\section{Память}
  \subsection{Виртуальная память}
    Есть 2 проблемы: нужно выделить каждому процессу память, при этому так, чтобы процессы не могли залазить в память друг друга. Вторая проблема: это то, что в ассемблерных командах нужны относительные сдвиги (???)
    \begin{itemize}
      \item Как процессам выделить персональное пространство?
      \item \todo{missing}
    \end{itemize}
  
  \subsection{Сегментная адресация}
    \begin{itemize}
      \item Память делится на куски разного размера -- сегменты
      \item За каждым процессом закрепляются несколько сегментов: сегмент с кодом, сегмент с данными, сегмент со стеком и так далее
      \item У такого подхода есть проблема: фрагментация памяти. В какой-то момент может быть ситуация, когда каждый второй байт занят и программа требует половину памяти; несмотря на то, что в реальности 50\% памяти свободно, выделить её невозможно
    \end{itemize}
  
  \subsection{Страничная адресация}
    \begin{itemize}
      \item Вся физическая память делится на \textbf{фреймы} -- куски равного размера (4096 байт на x86)
      \item Каждому процессу выделяется своё \textit{адресное пространство} или \textit{виртуальная память}
      \item Виртуальная память делится на \textbf{страницы} аналогично фреймам
      \item Каждой страницы в адресном пространстве может соответствовать какой-то фрейм
    \end{itemize}
  
    \begin{itemize}
      \item Как хранить отображения страниц во фреймы?
      \item Всего существует $\frac{2^{64}}{2^{12}} = 2^{52}$ страниц памяти
      \item Если каждая страница описывается 8 байтами, то потребуется $2^60$ байт в памяти
      \item \todo{missing}
    \end{itemize}
  
  \subsection{Multi-level page tables}
    \begin{itemize}
      \item Идея: давайте сделаем таблицы многоуровневыми -- сначала поделим всё пространство на части, каждую из этих частей еще на части и так далее
      \item Не храня лишние ``дыры'' мы будем экономить место
      \item Под x86 используются четырёхуровневые таблицы: P4, P3, P2, P1. Встречаются и пятиуровневые, но они сейчас мало распространены.
      \item Каждая таблица занимает ровно 4096 байт, содержит ровно 512 байт (\textit{PTE = page table entry}) по 8 байт и находится в начале страницы
      \item Каждая запись ссылается на начало следующей таблицы, последняя таблица ссылается на адрес фрейма
    \end{itemize}
    
\begin{figure}[h!]
  \includegraphics[width=\linewidth]{/Users/user/Downloads/X86_Paging_64bit.png}
  \caption{Multi-level page table}
  \label{fig:page_table}
\end{figure}  
    % все адреса здесь физические, пока еще нет понятия виртуальных адресов
  
  \subsection{Что хранится в PTE?}
    \begin{itemize}
      \item Индексация следующей таблицы или фрейма не занимает все 8 байт PTE
      \item Кроме неё в PTE есть еще специальные \textit{флаги страниц}
      \item Например, 1ый бит отвечает за то, будет ли страница доступна на запись
      \item 63ий -- за то, будет ли процессор исполнять код на этой странице
      \item Также в некоторые биты процессор сам пишет флаги, например, dirty-юит устанавливается всегда, когда происходит запись в страницу
      \item Флаги имеют иерархическую видимость: если в P2 writeable-бит равен 0, а в P4 -- 1, то страница будет доступна на запись
    \end{itemize}
  
  \subsection{Устройство виртуального адреса}
    \begin{itemize}
      \item На текущий момент x86-64 позволяет адресовать 48 бит физической памяти
      \item Старшие биты (с 48 по 63) должны быть sign extended копиями 47го бита
      \item Следующие биты (с 38 по 47) адресуют PTE в P4
      \item Биты с 29 по 37 адресуют PTE в P3
      \item Биты с 21 по 28 адресуют PTE в P2
      \item Биты с 12 по 20 адресуют PTE в P1, которая ссылает непосредственно на фрейм
      \item Биты с 0 по 11 адресуют смещение внутри фрейма
    \end{itemize}
  
    \subsection{ОС и таблицы страниц}
      \begin{itemize}
        \item Операционная система хранит таблицы страниц для каждого процесса
        \item Таблица страниц сменяется каждый раз, когда процессор переходит в другой поток
        \item В реальности каждое обращение к памяти не вызывает прыжки по таблицам, оно кэшируется в TLB (translation lookaside buffer)
        \item При переключении процесса TLB полностью сбрасывается (с оговорками)
      \end{itemize}
    
    \subsection{Выделение памяти: on-demand paging}
      \begin{itemize}
        \item Обычно современные ОС не выделяют всю запрошенную память сразу
        \item Page fault -- ситуация, когда нет запрашиваемой страницы в текущей таблице страниц
        \item Идея состоит в том, чтобы детектировать с помощью page fault'ов реальные обращение к памяти и только тогда её выделять
      \end{itemize}
    
    \subsection{Minor page fault}
      \begin{itemize}
        \item Кроме самих таблиц ОС обычно хранят свои отображения, запрошенные пользователем
        \item В Linux такие отображения называются VMA = virtual memore area
        \item Во время выделения памяти, ядро создаёт новый VMA
        \item При первом обращении происходит page fault, ядро выделяет фрейм и добавляет его в таблицу страниц
        \item Такой PF называют минорным (minor page fault)
      \end{itemize}
    
    \subsection{File memory mapping}
      \begin{itemize}
        \item Кроме выделения памяти POSIX позволяет мапить файлы в память
        \item Можно указать файл, оффсет в нём и адрес памяти
        \item По этому адресу памяти в текущем пространстве будет лежать (изменяемая) копия файла
        \item Изменения в других процессах будут сразу отображены в память
      \end{itemize}
    
    \subsection{Major page faults}
      \begin{itemize}
        \item За страницами, за которыми закреплён файл, скрывается механизм, который называется page caching
        \item Для них тоже используется on-demand paging: при первом обращении генерируется page fault, ядро перехватывает исключение, читает с диска файл и копирует его в память
        \item Такой PF называют мажорным (major page fault)
      \end{itemize}
    
    \subsection{Page cache}
      \begin{itemize}
        \item Страницы с данными файла из всех процессов ссылаются на один и тот же фрейм
        \item Поэтому изменения файлов (в том числе через write) видны во всей ОС сразу
        \item Однако, write не гарантирует, что данные были записаны на диск
      \end{itemize}
    
    \subsection{fsync}
\begin{lstlisting}[style=cpp]
int fsync(int fd);
\end{lstlisting}
Сконструировать оборудование так, чтобы оно точно записало что-то на диск, сложно (если не невозможно). Иногда бывает, что жесткие диски даже не предоставляют интерфейса для синхронизации данных. Поэтому \lsin{fsync} гарантирует, что данные дойдут до диска, но рассчитывать, что они точно запишутся, нельзя. Например, может произойти сбой в работе диска, и информация не будет записана. Используются различные способы предотвращения такого поведения. Например, на Mac-ах есть резервный источник питания, который используется для того, чтобы при выключении компьютера все данные сначала записались на диск (используя этот источник), и только потом произошло выключение. Похожие техники используются на серверах.

    \subsection{mmap и munmap}
\begin{lstlisting}[style=cpp]
void* mmap(void* addr, size_t length, int prot, int flags, int fd, off_t offset);
int munmap(void* addr, size_t length);
int mprotect(void* addr, size_t len, int prot);
\end{lstlisting}
%mprotect using in Java?

    \subsection{mmap}
      \todo{mmap}
    
    \subsection{mmap: prot}
      \begin{itemize}
        \item PROT\_EXEC -- процессор сможет выполнять код на этой странице
        \item PROT\_READ -- страницу будет доступна на чтения
        \item PROT\_WRITE -- страница будет доступна на запись
        \item PROT\_NONE -- к странице никак нельзя будет обратиться
      \end{itemize}
    
    \subsection{mmap: flags}
      \begin{itemize}
        \item MAP\_ANONYMOUS -- определяет, что облатсть будет анонимной, fd == -1
        \item MAP\_SHARED -- определяет, что область будет доступна детям текущего процесса
        \item MAP\_FIXED -- говорит ядру использовать \textit{в точности} адрес \lsin{addr} или вернуть ошибку
        \item MAP\_POPULATE -- говорит ядру сразу выделить физическую память для этой области (не будет использован механизм on-demand paging $\Rightarrow$ не будет minor fault-ов)
        \item Есть еще много флагов
      \end{itemize}
    
    \subsection{Псевдофайлы для контроля расхода памяти}
      \begin{itemize}
        \item /proc/<pid>/maps хранит текущие VMA
        \item /proc/<pid>/status содержит статус процесса, есть куча информации о памяти
        \item /proc/<pid>/mem представляет собой память процесса (её можно читать и писать)
        \item /proc/<pid>/map\_files хранит список файлов, которые замапленны в процесс
      \end{itemize}
    
    \subsection{Вытеснение страниц и swap}
      \begin{itemize}
        \item Если системе не хватает физической памяти для хранения анонимных страниц, она начинает их сбрасывать на диск
        \item Вытесенение анонимных страниц происходит в специальный swap файл или раздел диска (файл подкачки)
        \item Обычно это никак не заметно на приложениях, однако в условиях memory pressure это может приводить к странным последствиям
      \end{itemize}